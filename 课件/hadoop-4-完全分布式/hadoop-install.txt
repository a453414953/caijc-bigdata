hadoop  安装：

centos 6.5
jdk 1.8 
hadoop 2.6.5  

1基础设施：
	设置网络：
	设置IP
		*  大家自己看看自己的vm的编辑->虚拟网络编辑器->观察 NAT模式的地址 
	vi /etc/sysconfig/network-scripts/ifcfg-eth0
		DEVICE=eth0
		#HWADDR=00:0C:29:42:15:C2
		TYPE=Ethernet
		ONBOOT=yes
		NM_CONTROLLED=yes
		BOOTPROTO=static
		IPADDR=192.168.150.11
		NETMASK=255.255.255.0
		GATEWAY=192.168.150.2
		DNS1=223.5.5.5
		DNS2=114.114.114.114
	设置主机名
	vi /etc/sysconfig/network
		NETWORKING=yes
		HOSTNAME=node01
	设置本机的ip到主机名的映射关系
	vi /etc/hosts
		192.168.150.11 node01
		192.168.150.12 node02
	
	关闭防火墙
	service iptables stop
	chkconfig iptables off
	关闭 selinux
	vi /etc/selinux/config
		SELINUX=disabled
	
	做时间同步
	yum install ntp  -y
	vi /etc/ntp.conf
		server ntp1.aliyun.com
	service ntpd start
	chkconfig ntpd on
	
	安装JDK：
	rpm -i   jdk-8u181-linux-x64.rpm	
		*有一些软件只认：/usr/java/default
	vi /etc/profile     
		export  JAVA_HOME=/usr/java/default
		export PATH=$PATH:$JAVA_HOME/bin
	source /etc/profile   |  .    /etc/profile
 
	ssh免密：  ssh  localhost  1,验证自己还没免密  2,被动生成了  /root/.ssh
		ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
		cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
		如果A 想  免密的登陆到B：
			A：
				ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
			B：
				cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
		结论：B包含了A的公钥，A就可以免密的登陆
			你去陌生人家里得撬锁
			去女朋友家里：拿钥匙开门
2，Hadoop的配置（应用的搭建过程）
	规划路径：
	mkdir /opt/bigdata
	tar xf hadoop-2.6.5.tar.gz
	mv hadoop-2.6.5  /opt/bigdata/
	pwd
		/opt/bigdata/hadoop-2.6.5
	
	vi /etc/profile	
		export  JAVA_HOME=/usr/java/default
		export HADOOP_HOME=/opt/bigdata/hadoop-2.6.5
		export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
	source /etc/profile
	
	配置hadoop的角色：
	cd   $HADOOP_HOME/etc/hadoop
		必须给hadoop配置javahome要不ssh过去找不到
	vi hadoop-env.sh
		export JAVA_HOME=/usr/java/default
		给出NN角色在哪里启动
	vi core-site.xml
		    <property>
				<name>fs.defaultFS</name>
				<value>hdfs://node01:9000</value>
			</property>
		配置hdfs  副本数为1.。。。
	vi hdfs-site.xml
		    <property>
				<name>dfs.replication</name>
				<value>1</value>
			</property>
			<property>
				<name>dfs.namenode.name.dir</name>
				<value>/var/bigdata/hadoop/local/dfs/name</value>
			</property>
			<property>
				<name>dfs.datanode.data.dir</name>
				<value>/var/bigdata/hadoop/local/dfs/data</value>
			</property>
			<property>
				<name>dfs.namenode.secondary.http-address</name>
				<value>node01:50090</value>
			</property>
			<property>
				<name>dfs.namenode.checkpoint.dir</name>
				<value>/var/bigdata/hadoop/local/dfs/secondary</value>
			</property>


		配置DN这个角色再那里启动
	vi slaves
		node01

3,初始化&启动：
	hdfs namenode -format  
		创建目录
		并初始化一个空的fsimage
		VERSION
			CID
	
	start-dfs.sh
		第一次：datanode和secondary角色会初始化创建自己的数据目录
		
	http://node01:50070
		修改windows： C:\Windows\System32\drivers\etc\hosts
			192.168.150.11 node01
			192.168.150.12 node02
			192.168.150.13 node03
			192.168.150.14 node04

4，简单使用：
	hdfs dfs -mkdir /bigdata
	hdfs dfs -mkdir  -p  /user/root



5,验证知识点：
	cd   /var/bigdata/hadoop/local/dfs/name/current
		观察 editlog的id是不是再fsimage的后边
	cd /var/bigdata/hadoop/local/dfs/secondary/current
		SNN 只需要从NN拷贝最后时点的FSimage和增量的Editlog


	hdfs dfs -put hadoop*.tar.gz  /user/root
	cd  /var/bigdata/hadoop/local/dfs/data/current/BP-281147636-192.168.150.11-1560691854170/current/finalized/subdir0/subdir0
		

	for i in `seq 100000`;do  echo "hello hadoop $i"  >>  data.txt  ;done
	hdfs dfs -D dfs.blocksize=1048576  -put  data.txt 
	cd  /var/bigdata/hadoop/local/dfs/data/current/BP-281147636-192.168.150.11-1560691854170/current/finalized/subdir0/subdir0
	检查data.txt被切割的块，他们数据什么样子
 
----------------------------------------------------------------------------------------- 

伪分布式：  在一个节点启动所有的角色： NN,DN,SNN
完全分布式：
	基础环境
	部署配置
		1）角色在哪里启动
			NN： core-site.xml:  fs.defaultFS  hdfs://node01:9000
			DN:  slaves:  node01
			SNN: hdfs-siet.xml:  dfs.namenode.secondary.http.address node01:50090
		2) 角色启动时的细节配置：
			dfs.namenode.name.dir  
			dfs.datanode.data.dir
	初始化&启动
		格式化
			Fsimage
			VERSION
		start-dfs.sh
			加载我们的配置文件
			通过ssh 免密的方式去启动相应的角色

伪分布式到完全分布式：角色重新规划

	node01:
		stop-dfs.sh
	
	ssh 免密是为了什么 ：  启动start-dfs.sh：  在哪里启动，那台就要对别人公开自己的公钥
		这一台有什么特殊要求吗： 没有
	node02~node04:
		rpm -i jdk....
	node01:
		scp /root/.ssh/id_dsa.pub  node02:/root/.ssh/node01.pub
		scp /root/.ssh/id_dsa.pub  node03:/root/.ssh/node01.pub
		scp /root/.ssh/id_dsa.pub  node04:/root/.ssh/node01.pub
	node02:
		cd ~/.ssh
		cat node01.pub >> authorized_keys
	node03:
		cd ~/.ssh
		cat node01.pub >> authorized_keys
	node04:
		cd ~/.ssh
		cat node01.pub >> authorized_keys

配置部署：
	node01:
		cd $HADOOP/etc/hadoop
		vi core-site.xml    不需要改
		vi hdfs-site.xml
			    <property>
				<name>dfs.replication</name>
				<value>2</value>
			    </property>
			    <property>
				<name>dfs.namenode.name.dir</name>
				<value>/var/bigdata/hadoop/full/dfs/name</value>
			    </property>
			    <property>
				<name>dfs.datanode.data.dir</name>
				<value>/var/bigdata/hadoop/full/dfs/data</value>
			    </property>
			    <property>
				<name>dfs.namenode.secondary.http-address</name>
				<value>node02:50090</value>
			    </property>
			    <property>
				<name>dfs.namenode.checkpoint.dir</name>
				<value>/var/bigdata/hadoop/full/dfs/secondary</value>
			    </property>
		vi slaves
			node02
			node03
			node04

		分发：
			cd /opt
			scp -r ./bigdata/  node02:`pwd`
			scp -r ./bigdata/  node03:`pwd`
			scp -r ./bigdata/  node04:`pwd`

		格式化启动
			hdfs namenode -format
			start-dfs.sh
			
-----------------------------------------------------

做减法：
作业：笔记~！
发到群里
人名作为笔记的文件名
周六晚上之前



























































